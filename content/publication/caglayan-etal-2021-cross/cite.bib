@inproceedings{caglayan-etal-2021-cross,
 abstract = {Pre-trained language models have been shown to improve performance in many natural language tasks substantially. Although the early focus of such models was single language pre-training, recent advances have resulted in cross-lingual and visual pre-training methods. In this paper, we combine these two approaches to learn visually-grounded cross-lingual representations. Specifically, we extend the translation language modelling (Lample and Conneau, 2019) with masked region classification and perform pre-training with three-way parallel vision & language corpora. We show that when fine-tuned for multimodal machine translation, these models obtain state-of-the-art performance. We also provide qualitative insights into the usefulness of the learned grounded representations.},
 address = {Online},
 author = {Caglayan, Ozan  and
Kuyu, Menekse  and
Amac, Mustafa Sercan  and
Madhyastha, Pranava  and
Erdem, Erkut  and
Erdem, Aykut  and
Specia, Lucia},
 booktitle = {Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
 month = {April},
 pages = {1317--1324},
 publisher = {Association for Computational Linguistics},
 title = {Cross-lingual Visual Pre-training for Multimodal Machine Translation},
 url = {https://www.aclweb.org/anthology/2021.eacl-main.112},
 year = {2021}
}

