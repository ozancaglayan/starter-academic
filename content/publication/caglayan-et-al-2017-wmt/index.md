---
# Documentation: https://wowchemy.com/docs/managing-content/

title: LIUM-CVC Submissions for WMT17 Multimodal Translation Task
subtitle: ''
summary: ''
authors:
- Ozan Caglayan
- Walid Aransa
- Adrien Bardet
- Mercedes Garcı́a-Mart\ńez
- Fethi Bougares
- Loı̈c Barrault
- Marc Masana
- Luis Herranz
- Joost van de Weijer
tags: []
categories: []
date: '2017-09-01'
lastmod: 2021-02-05T23:30:55Z
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-02-05T23:33:44.811832Z'
publication_types:
- '1'
abstract: This paper describes the monomodal and multimodal Neural Machine Translation
  systems developed by LIUM and CVC for WMT17 Shared Task on Multimodal Translation.
  We mainly explored two multimodal architectures where either global visual features
  or convolutional feature maps are integrated in order to benefit from visual context.
  Our final systems ranked first for both En-De and En-Fr language pairs according
  to the automatic evaluation metrics METEOR and BLEU.
publication: '*Proceedings of the Second Conference on Machine Translation, Volume
  2: Shared Task Papers*'
url_pdf: https://arxiv.org/pdf/1707.04481
---
