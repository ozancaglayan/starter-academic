---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Multimodal machine translation through visuals and speech
subtitle: ''
summary: ''
authors:
- Umut Sulubacak
- Ozan Caglayan
- Stig-Arne Grönroos
- Aku Rouhe
- Desmond Elliott
- Lucia Specia
- Jörg Tiedemann
tags: []
categories: []
date: '2020-01-01'
lastmod: 2021-02-06T00:00:33Z
featured: true
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-02-06T00:00:33.824981Z'
publication_types:
- '2'
abstract: 'Multimodal machine translation involves drawing information from more than
  one modality, based on the assumption that the additional modalities will contain
  useful alternative views of the input data. The most prominent tasks in this area
  are spoken language translation, image-guided translation, and video-guided translation,
  which exploit audio and visual modalities, respectively. These tasks are distinguished
  from their monolingual counterparts of speech recognition, image captioning, and
  video captioning by the requirement of models to generate outputs in a different
  language. This survey reviews the major data resources for these tasks, the evaluation
  campaigns concentrated around them, the state of the art in end-to-end and pipeline
  approaches, and also the challenges in performance evaluation. The paper concludes
  with a discussion of directions for future research in these areas: the need for
  more expansive and challenging datasets, for targeted evaluations of model performance,
  and for multimodality in both the input and output space.'
publication: '*Machine Translation*'
url_pdf: https://arxiv.org/pdf/1911.12798
---
